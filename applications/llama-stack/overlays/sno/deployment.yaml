---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: llamastack-deployment
spec:
  template:
    spec:
      containers:
        - name: llamastack
          env:
            - name: MAX_TOKENS
              value: '128000'
            - name: VLLM_MAX_TOKENS
              value: '128000'
            - name: LLAMA3B_URL
              value: 'https://sno-llama32-3b-vllm-predictor-llama-serving.apps.sno.sandbox2556.opentlc.com/v1'
            - name: LLAMA3B_MODEL
              value: Llama-3.2-3B-Instruct-Q8_0.gguf
            - name: GRANITE_URL
              value: 'https://sno-granite32-vllm-predictor-llama-serving.apps.sno.sandbox2556.opentlc.com/v1'
            - name: GRANITE_MODEL
              value: granite-3.2-2b-instruct
            - name: QWEN_URL
              value: 'https://sno-qwen31-cpp-predictor-llama-serving.apps.sno.sandbox2556.opentlc.com/v1'
            - name: QWEN_MODEL
              value: /mnt/models/Qwen3-1.7B-Q8_0.gguf
            - name: DEEPSEEK_URL
              value: 'https://sno-deepseek-qwen3-vllm-predictor-llama-serving.apps.sno.sandbox2556.opentlc.com/v1'
            - name: DEEPSEEK_MODEL
              value: deepseek-r1-0528-qwen3-8b-bnb-4bit
            - name: VLLM_API_TOKEN
              value: fake
            - name: CUSTOM_TIKTOKEN_CACHE_DIR
              value: /app/cache
            - name: MILVUS_DB_PATH
              value: milvus.db
            - name: LLAMA_STACK_LOGGING
              value: all=debug

